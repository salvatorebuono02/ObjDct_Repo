{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a tiny version of YOLO with DIOR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement YOLO architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearActivation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, t):\n",
    "        return torch.pow(t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyissimoYOLO(nn.Module):\n",
    "    def __init__(self, B=2, num_classes=1, S=4):\n",
    "        super(TinyissimoYOLO, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            LinearActivation(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            LinearActivation(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            LinearActivation(),\n",
    "            nn.AvgPool2d(kernel_size=2,stride = 2)\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            LinearActivation(),\n",
    "            nn.AvgPool2d(kernel_size=2,stride = 2)\n",
    "        )\n",
    "\n",
    "        self.fclayers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*5*5, 256),\n",
    "            LinearActivation(),\n",
    "            nn.Linear(256, S*S*(num_classes + 3 * B)),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.fclayers(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model = TinyissimoYOLO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyissimoYOLO                           [1, 112]                  --\n",
       "├─Sequential: 1-1                        [1, 16, 44, 44]           --\n",
       "│    └─Conv2d: 2-1                       [1, 16, 88, 88]           448\n",
       "│    └─LinearActivation: 2-2             [1, 16, 88, 88]           --\n",
       "│    └─AvgPool2d: 2-3                    [1, 16, 44, 44]           --\n",
       "├─Sequential: 1-2                        [1, 32, 22, 22]           --\n",
       "│    └─Conv2d: 2-4                       [1, 32, 44, 44]           4,640\n",
       "│    └─LinearActivation: 2-5             [1, 32, 44, 44]           --\n",
       "│    └─AvgPool2d: 2-6                    [1, 32, 22, 22]           --\n",
       "├─Sequential: 1-3                        [1, 64, 11, 11]           --\n",
       "│    └─Conv2d: 2-7                       [1, 64, 22, 22]           18,496\n",
       "│    └─LinearActivation: 2-8             [1, 64, 22, 22]           --\n",
       "│    └─AvgPool2d: 2-9                    [1, 64, 11, 11]           --\n",
       "├─Sequential: 1-4                        [1, 128, 5, 5]            --\n",
       "│    └─Conv2d: 2-10                      [1, 128, 11, 11]          73,856\n",
       "│    └─LinearActivation: 2-11            [1, 128, 11, 11]          --\n",
       "│    └─AvgPool2d: 2-12                   [1, 128, 5, 5]            --\n",
       "├─Sequential: 1-5                        [1, 112]                  --\n",
       "│    └─Flatten: 2-13                     [1, 3200]                 --\n",
       "│    └─Linear: 2-14                      [1, 256]                  819,456\n",
       "│    └─LinearActivation: 2-15            [1, 256]                  --\n",
       "│    └─Linear: 2-16                      [1, 112]                  28,784\n",
       "==========================================================================================\n",
       "Total params: 945,680\n",
       "Trainable params: 945,680\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 31.19\n",
       "==========================================================================================\n",
       "Input size (MB): 0.09\n",
       "Forward/backward pass size (MB): 1.86\n",
       "Params size (MB): 3.78\n",
       "Estimated Total Size (MB): 5.74\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(1, 3, 88, 88))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(center_preds, center_labels):\n",
    "    \"\"\"\n",
    "    Calculate euclidean distance\n",
    "    Parameters:\n",
    "        center_preds: predictions of centers (BATCH_SIZE, 2)\n",
    "        center_labels: target of centers of shape (BATCH_SIZE, 2)\n",
    "    Returns:\n",
    "        distance: euclidean distance for all examples\n",
    "    \"\"\"\n",
    "\n",
    "    x1 = center_preds[..., 0:1]\n",
    "    y1 = center_preds[..., 1:2]\n",
    "    x2 = center_labels[..., 0:1]\n",
    "    y2 = center_labels[..., 1:2]\n",
    "\n",
    "    distance = torch.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_center_inside_bbox(center, bbox):\n",
    "    \"\"\"\n",
    "    Check if a center (x, y) is inside a bounding box (x, y, w, h).\n",
    "    Parameters:\n",
    "        center (tuple): The (x, y) coordinates of the center.\n",
    "        bbox (tuple): The (x, y, w, h) coordinates of the bounding box.\n",
    "    Returns:\n",
    "        bool: True if the center is inside the bounding box, False otherwise.\n",
    "    \"\"\"\n",
    "    center_x, center_y = center\n",
    "    bbox_x, bbox_y, bbox_w, bbox_h = bbox\n",
    "\n",
    "    bbox_x_min = bbox_x - bbox_w / 2\n",
    "    bbox_x_max = bbox_x + bbox_w / 2\n",
    "    bbox_y_min = bbox_y - bbox_h / 2\n",
    "    bbox_y_max = bbox_y + bbox_h / 2\n",
    "\n",
    "    return bbox_x_min <= center_x <= bbox_x_max and bbox_y_min <= center_y <= bbox_y_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(\n",
    "    pred_boxes, true_boxes, num_classes=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates mean average precision \n",
    "    Parameters:\n",
    "        pred_boxes (list): list of lists containing all bboxes with each bbox\n",
    "        specified as [train_idx, class_prediction, prob_score, x_center, y_center]\n",
    "        true_boxes (list): Similar as pred_boxes except all the correct ones \n",
    "        specified as [train_idx, class_label, x, y, w, h]\n",
    "        num_classes (int): number of classes\n",
    "    Returns:\n",
    "        float: mAP value across all classes \n",
    "    \"\"\"\n",
    "    average_precisions = []\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "\n",
    "        for detection in pred_boxes:\n",
    "            if detection[1] == c:\n",
    "                detections.append(detection)\n",
    "\n",
    "        for true_box in true_boxes:\n",
    "            if true_box[1] == c:\n",
    "                ground_truths.append(true_box)\n",
    "\n",
    "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "\n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros((len(detections)))\n",
    "        FP = torch.zeros((len(detections)))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            ground_truth_img = [\n",
    "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
    "            ]\n",
    "\n",
    "            best_match = False\n",
    "\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                if is_center_inside_bbox(detection[3:5], gt[2:]):\n",
    "                    best_match = True\n",
    "                    best_gt_idx = idx\n",
    "                    break\n",
    "\n",
    "            if best_match:\n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "                    TP[detection_idx] = 1\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "\n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "        precisions = torch.divide(TP_cumsum, (TP_cumsum + FP_cumsum + epsilon))\n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "        average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "    return sum(average_precisions) / len(average_precisions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Max Suppression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(centers, threshold, distance_threshold):\n",
    "\n",
    "    assert type(centers) == list\n",
    "    centers = [center for center in centers if center[1]> threshold]\n",
    "    centers = sorted(centers, key=lambda x: x[1], reverse=True)\n",
    "    centers_after_nms = []\n",
    "\n",
    "    while centers:\n",
    "        current_center = centers.pop(0)\n",
    "        centers = [\n",
    "            center\n",
    "            for center in centers\n",
    "            if center[0] != current_center[0]\n",
    "            or euclidean_distance(\n",
    "                torch.tensor(current_center[3:5]).unsqueeze(0),\n",
    "                torch.tensor(center[3:5]).unsqueeze(0),\n",
    "            )\n",
    "            > distance_threshold\n",
    "        ]\n",
    "\n",
    "        centers_after_nms.append(current_center)\n",
    "        \n",
    "    return centers_after_nms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and convert centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(\n",
    "    loader,\n",
    "    model,\n",
    "    threshold,\n",
    "    distance_threshold,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    all_pred_centers = []\n",
    "    all_true_centers = []\n",
    "    all_true_boxes = []\n",
    "\n",
    "    # make sure model is in eval before get bboxes\n",
    "    model.eval()\n",
    "    train_idx = 0\n",
    "\n",
    "    for batch_idx, (x, labels, boxes_list) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(x)\n",
    "\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        true_centers = cellcenters_to_centers(labels) # type: ignore\n",
    "        pred_centers = cellcenters_to_centers(predictions) # type: ignore\n",
    "        \n",
    "        \n",
    "\n",
    "        for idx in range(batch_size):\n",
    "\n",
    "            boxes = boxes_list[idx].to(device)\n",
    "\n",
    "            # nms_centers= non_max_suppression(\n",
    "            #     pred_centers[idx],\n",
    "            #     threshold=threshold,\n",
    "            #     distance_threshold=distance_threshold,\n",
    "            # )\n",
    "\n",
    "            # for center in nms_centers:\n",
    "            #     all_pred_centers.append([train_idx] + center)\n",
    "\n",
    "            for center in pred_centers[idx]:\n",
    "                if center[1] > 0:\n",
    "                    all_pred_centers.append([train_idx] + center)\n",
    "\n",
    "            for center in true_centers[idx]:\n",
    "                if center[1] > 0:\n",
    "                    all_true_centers.append([train_idx] + center)\n",
    "\n",
    "            for box in boxes:\n",
    "                all_true_boxes.append([train_idx] + box.tolist())\n",
    "\n",
    "            train_idx += 1\n",
    "\n",
    "    model.train()\n",
    "    return all_pred_centers, all_true_centers, all_true_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cellcenters(predictions, S=4, C=1):\n",
    "    \"\"\"\n",
    "    Converts predictions from the model to centers\n",
    "    \"\"\"\n",
    "    predictions = predictions.to(\"cpu\")\n",
    "    batch_size = predictions.shape[0]\n",
    "    predictions = predictions.reshape(batch_size, S, S, C + 6)\n",
    "\n",
    "    centers1 = predictions[..., C + 1:C + 3]\n",
    "    centers2 = predictions[..., C + 4:C + 6]\n",
    "    \n",
    "    scores = torch.cat(\n",
    "        (predictions[..., C].unsqueeze(0), predictions[..., C + 3].unsqueeze(0)), dim=0\n",
    "    )\n",
    "    best_center = scores.argmax(0).unsqueeze(-1)\n",
    "\n",
    "    best_centers = centers1 * (1 - best_center) + best_center * centers2\n",
    "\n",
    "    # This results in a tensor with shape (batch_size, 7, 7, 1) where each element represents the index of a grid cell.\n",
    "    cell_indices = torch.arange(S).repeat(batch_size, S, 1).unsqueeze(-1)\n",
    "    x = 1 / S * (best_centers[..., :1] + cell_indices)\n",
    "    # Permute because is used here to swap these indices to match the (x, y) convention used in the best_boxes tensor.\n",
    "    # [0,1,2]->[0,0,0]\n",
    "    # [0,1,2]->[1,1,1]\n",
    "    # [0,1,2]->[2,2,2]\n",
    "    y = 1 / S * (best_centers[..., 1:2] + cell_indices.permute(0, 2, 1, 3))\n",
    "    converted_centers = torch.cat((x, y), dim=-1)\n",
    "    predicted_class = predictions[..., :C].argmax(-1).unsqueeze(-1)\n",
    "    best_confidence = torch.max(predictions[..., C], predictions[..., C + 3]).unsqueeze(\n",
    "        -1\n",
    "    )\n",
    "    \n",
    "    converted_preds = torch.cat(\n",
    "        (predicted_class, best_confidence, converted_centers), dim=-1\n",
    "    )\n",
    "\n",
    "    return converted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cellcenters_to_centers(out, S=4):\n",
    "    converted_pred = convert_cellcenters(out).reshape(out.shape[0], S * S, -1)\n",
    "    converted_pred[..., 0] = converted_pred[..., 0].long()\n",
    "    all_centers = []\n",
    "\n",
    "    for ex_idx in range(out.shape[0]):\n",
    "        centers = []\n",
    "        for center_idx in range(S * S):\n",
    "            centers.append([x.item() for x in converted_pred[ex_idx, center_idx, :]])\n",
    "        all_centers.append(centers)\n",
    "        \n",
    "    return all_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Loader of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, centers):\n",
    "        for t in self.transforms:\n",
    "            img, centers = t(img), centers\n",
    "\n",
    "        return img, centers\n",
    "\n",
    "\n",
    "transform = Compose([transforms.Resize((88, 88)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, S=4, B=2, C=1, transform=None, train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.train = train\n",
    "\n",
    "        # Determine the directory of the images and labels\n",
    "        self.img_dir = os.path.join(self.root_dir, 'images')\n",
    "        self.label_dir = os.path.join(self.root_dir, 'label')\n",
    "\n",
    "        self.img_ids = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.img_ids[index].split('.')[0]\n",
    "        centers = []\n",
    "        boxes = []\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, img_id + '.jpg')\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        # Load labels\n",
    "        label_path = os.path.join(self.label_dir, img_id + '.txt')\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                class_label, x, y, width, height = map(float, line.strip().split())\n",
    "                centers.append([class_label, x, y])\n",
    "                boxes.append([class_label, x, y, width, height])\n",
    "        \n",
    "        if len(boxes) > 3:\n",
    "            boxes = boxes[:3]\n",
    "            centers = centers[:3]\n",
    "\n",
    "        boxes = torch.tensor(boxes)\n",
    "        centers = torch.tensor(centers)        \n",
    "        if self.transform:\n",
    "            image, centers = self.transform(image, centers)\n",
    "        # Convert To Cells\n",
    "        label_matrix = torch.zeros((self.S, self.S, self.C + 3 * self.B))\n",
    "        for center in centers:\n",
    "            class_label, x, y = center\n",
    "            class_label = int(class_label)\n",
    "            i, j = int(self.S * y), int(self.S * x)\n",
    "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
    "\n",
    "            if label_matrix[i, j, self.C] == 0:\n",
    "                label_matrix[i, j, self.C] = 1\n",
    "\n",
    "                center_coordinates = torch.tensor(\n",
    "                    [x_cell, y_cell]\n",
    "                )\n",
    "\n",
    "                label_matrix[i, j, self.C + 1:self.C + 3] = center_coordinates\n",
    "                label_matrix[i, j, class_label] = 1\n",
    "    \n",
    "        #print(f\"label_matrix shape: {label_matrix.shape}\")\n",
    "\n",
    "        return image, label_matrix , boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From original paper: \n",
    ">   YOLO predicts multiple bounding boxes per grid cell. At training time we only want one bounding box predictor to be responsible for each object. We assign one predictor to be “responsible” for predicting an object based on which prediction has the highest current IOU with the ground truth. This leads to specialization between the bounding box predictors.\n",
    "Each predictor gets better at predicting certain sizes, aspect ratios, or classes of object, improving overall recall. \n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\lambda_{\\text {coord }} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(x_i-\\hat{x}_i\\right)^2+\\left(y_i-\\hat{y}_i\\right)^2\\right] \\\\\n",
    "+\\lambda_{\\text {coord }} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(\\sqrt{w_i}-\\sqrt{\\hat{w}_i}\\right)^2+\\left(\\sqrt{h_i}-\\sqrt{\\hat{h}_i}\\right)^2\\right] \\\\\n",
    "+\\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {obj }}\\left(C_i-\\hat{C}_i\\right)^2 \\\\\n",
    "+\\lambda_{\\text {noobj }} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {noobj }}\\left(C_i-\\hat{C}_i\\right)^2 \\\\\n",
    "+\\sum_{i=0}^{S^2} \\mathbb{1}_i^{\\text {obj }} \\sum_{c \\in \\text { classes }}\\left(p_i(c)-\\hat{p}_i(c)\\right)^2\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "During training we optimize the following, multi-part where $ 1_{obj}^i $ denotes if object appears in cell **i** and $1_{obj}^{ij}$ denotes that the **j**  bounding box predictor in cell i is “responsible” for that prediction.\n",
    "\n",
    "In every image many grid cells do not contain any object. This pushes the “confidence” scores of those cells towards zero, often overpowering the gradient from cells that do contain objects. This can lead to model instability, as the model may prioritize learning to predict empty cells rather than focusing on correctly detecting objects in cells containing them, causing training to diverge early on. To remedy this, we increase the loss from bounding box coordinate predictions and decrease the loss from confidence predictions for boxes that don’t contain objects. We use two parameters, $\\lambda_{coord}$ and $\\lambda_{noobj}$  to accomplish this.\n",
    "\n",
    "Note that the loss function only penalizes classification error if an object is present in that grid cell (hence the conditional class probability discussed earlier). It also only penalizes bounding box coordinate error if that predictor is “responsible” for the ground truth box (i.e. has the highest\n",
    "IOU of any predictor in that grid cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculate the loss for yolo (v1) model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, S=4, B=2, C=1):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "        \"\"\"\n",
    "        S is split size of image (in paper 7),\n",
    "        B is number of boxes (in paper 2),\n",
    "        C is number of classes (in paper 20, in dataset 3),\n",
    "        \"\"\"\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        # These are from Yolo paper, signifying how much we should\n",
    "        # pay loss for no object (noobj) and the box coordinates (coord)\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        # predictions are shaped (BATCH_SIZE, S*S(C+B*3) when inputted\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 3)\n",
    "        # Calculate IoU for the two predicted bounding boxes with target bbox\n",
    "        iou_c1 = euclidean_distance(predictions[..., self.C + 1:self.C + 3], target[..., self.C + 1:self.C + 3])\n",
    "        iou_c2 = euclidean_distance(predictions[..., self.C + 4:self.C + 6], target[..., self.C + 1:self.C + 3])\n",
    "        ious = torch.cat([iou_c1.unsqueeze(0), iou_c2.unsqueeze(0)], dim=0)\n",
    "        # Take the box with highest IoU out of the two prediction\n",
    "        # Note that bestbox will be indices of 0, 1 for which bbox was best\n",
    "        iou_maxes, bestcenter = torch.max(ious, dim=0)\n",
    "        exists_center = target[..., self.C].unsqueeze(3)  # in paper this is Iobj_i\n",
    "        \n",
    "        # ======================== #\n",
    "        #   FOR CENTER COORDINATES #\n",
    "        # ======================== #\n",
    "\n",
    "        # Set boxes with no object in them to 0. We only take out one of the two \n",
    "        # predictions, which is the one with highest Iou calculated previously.\n",
    "\n",
    "        center_predictions = exists_center * (\n",
    "            (\n",
    "                bestcenter * predictions[..., self.C + 4:self.C + 6]\n",
    "                + (1 - bestcenter) * predictions[..., self.C + 1:self.C + 3]\n",
    "            )\n",
    "        )\n",
    "        center_targets = exists_center * target[..., self.C + 1:self.C + 3]\n",
    "\n",
    "        center_loss = self.mse(\n",
    "            torch.flatten(center_predictions, end_dim=-2),\n",
    "            torch.flatten(center_targets, end_dim=-2),\n",
    "        )\n",
    "\n",
    "        # ==================== #\n",
    "        #   FOR OBJECT LOSS    #\n",
    "        # ==================== #\n",
    "\n",
    "        # pred_box is the confidence score for the bbox with highest IoU\n",
    "        pred_center = (\n",
    "            bestcenter * predictions[..., self.C + 3:self.C + 4] + (1 - bestcenter) * predictions[..., self.C:self.C + 1]\n",
    "        )\n",
    "\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_center * pred_center),\n",
    "            torch.flatten(exists_center * target[..., self.C:self.C + 1]),\n",
    "        )\n",
    "\n",
    "        # ======================= #\n",
    "        #   FOR NO OBJECT LOSS    #\n",
    "        # ======================= #\n",
    "\n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1 - exists_center) * predictions[..., self.C:self.C + 1], start_dim=1),\n",
    "            torch.flatten((1 - exists_center) * target[..., self.C:self.C + 1], start_dim=1),\n",
    "        )\n",
    "\n",
    "        no_object_loss += self.mse(\n",
    "            torch.flatten((1 - exists_center) * predictions[..., self.C + 3:self.C + 4], start_dim=1),\n",
    "            torch.flatten((1 - exists_center) * target[..., self.C:self.C + 1], start_dim=1)\n",
    "        )\n",
    "\n",
    "        # ================== #\n",
    "        #   FOR CLASS LOSS   #\n",
    "        # ================== #\n",
    "\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_center * predictions[..., :self.C], end_dim=-2,),\n",
    "            torch.flatten(exists_center * target[..., :self.C], end_dim=-2,),\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            self.lambda_coord * center_loss  # first two rows in paper\n",
    "            + object_loss  # third row in paper\n",
    "            + self.lambda_noobj * no_object_loss  # forth row\n",
    "            + class_loss  # fifth row\n",
    "        )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 32 # 64 in original paper but resource exhausted error otherwise.\n",
    "WEIGHT_DECAY = 0\n",
    "EPOCHS = 100\n",
    "LOAD_MODEL = False\n",
    "LOAD_MODEL_FILE = \"fomo.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, optimizer, loss_fn):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    mean_loss = []\n",
    "    \n",
    "    for batch_idx, (x, y,boxes) in enumerate(loop):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        mean_loss.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss = loss.item())\n",
    "        \n",
    "    print(f\"Mean loss was {sum(mean_loss) / len(mean_loss)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    label_matrices = []\n",
    "    boxes_list = []\n",
    "    for item in batch:\n",
    "        images.append(item[0])\n",
    "        label_matrices.append(item[1])\n",
    "        boxes_list.append(item[2])\n",
    "    images = torch.stack(images)\n",
    "    label_matrices = torch.stack(label_matrices)\n",
    "    return images, label_matrices, boxes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arch/ObjDct_Repo/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "files_dir = 'one_class_data'\n",
    "model = TinyissimoYOLO().to(DEVICE)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience=3, mode='max', verbose=True)\n",
    "loss_fn = YoloLoss()\n",
    "\n",
    "\n",
    "train_dataset = DiorDataset(\n",
    "    root_dir=files_dir,\n",
    "    transform=transform,\n",
    "    train=True\n",
    ")\n",
    "\n",
    "\n",
    "# Define the length of the training set\n",
    "train_len = int(0.8 * len(train_dataset))\n",
    "\n",
    "# Define the length of the test set\n",
    "test_len = len(train_dataset) - train_len\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_len, test_len])\n",
    "\n",
    "# Now you can create your DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  9.16it/s, loss=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 179.2894641331264\n",
      "mAP: 0.3618021607398987\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.56it/s, loss=75.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 106.01712145124164\n",
      "mAP: 0.3391192853450775\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.59it/s, loss=41.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 71.89844635554722\n",
      "mAP: 0.4143396019935608\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.59it/s, loss=33.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 63.04528318132673\n",
      "mAP: 0.3377811908721924\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.67it/s, loss=52.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 59.23813056945801\n",
      "mAP: 0.4039820432662964\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.65it/s, loss=58.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 56.77009746006557\n",
      "mAP: 0.4164489209651947\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.69it/s, loss=40.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 55.149058886936736\n",
      "mAP: 0.5047966837882996\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.61it/s, loss=38.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 54.01202065604074\n",
      "mAP: 0.4153566062450409\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.70it/s, loss=36.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 53.29702990395682\n",
      "mAP: 0.4965479373931885\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.62it/s, loss=40.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 52.717609541756765\n",
      "mAP: 0.3537937104701996\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.71it/s, loss=35.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 52.404057366507395\n",
      "mAP: 0.448469340801239\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.68it/s, loss=40.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 52.140074729919434\n",
      "mAP: 0.4738176167011261\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.62it/s, loss=45.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 51.861739703587126\n",
      "mAP: 0.49484360218048096\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.67it/s, loss=44.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 51.449966294424875\n",
      "mAP: 0.5081233382225037\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.64it/s, loss=45]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 51.31542655399868\n",
      "mAP: 0.5043264627456665\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.71it/s, loss=35.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 51.1848543712071\n",
      "mAP: 0.4887242615222931\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.54it/s, loss=35.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.87536266871861\n",
      "mAP: 0.5549024343490601\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.59it/s, loss=38.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.95702975136893\n",
      "mAP: 0.4402002692222595\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.64it/s, loss=44.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.656701360430034\n",
      "mAP: 0.5378744602203369\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.64it/s, loss=35.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.40839712960379\n",
      "mAP: 0.5676244497299194\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.68it/s, loss=37.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.42851734161377\n",
      "mAP: 0.5752015709877014\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.65it/s, loss=41]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.3910128729684\n",
      "mAP: 0.5702216029167175\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.63it/s, loss=29.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.14455073220389\n",
      "mAP: 0.48313233256340027\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.66it/s, loss=42.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.067570958818706\n",
      "mAP: 0.5635621547698975\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.55it/s, loss=40.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.01555946895054\n",
      "mAP: 0.5862026214599609\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.59it/s, loss=46]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.00349848611014\n",
      "mAP: 0.5847446322441101\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.60it/s, loss=44.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.80814797537668\n",
      "mAP: 0.5869143009185791\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.60it/s, loss=37.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.76255580357143\n",
      "mAP: 0.5074425935745239\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.63it/s, loss=32.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.82780524662563\n",
      "mAP: 0.5940737128257751\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  9.07it/s, loss=39.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.888557297842844\n",
      "mAP: 0.5622046589851379\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  8.80it/s, loss=37.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.677322796412874\n",
      "mAP: 0.4976963996887207\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  8.93it/s, loss=34.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.71958555494036\n",
      "mAP: 0.5931949615478516\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  9.10it/s, loss=38.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.69718728746687\n",
      "mAP: 0.4964064359664917\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  9.24it/s, loss=35.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.89608873639788\n",
      "mAP: 0.5511354804039001\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=43]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.57251698630197\n",
      "mAP: 0.4459593594074249\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=46.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.55244473048619\n",
      "mAP: 0.5229516625404358\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.43it/s, loss=45.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.434915678841726\n",
      "mAP: 0.5884321928024292\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.56it/s, loss=37.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.57431493486677\n",
      "mAP: 0.5844243168830872\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=33.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.420568874904085\n",
      "mAP: 0.4423474371433258\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=41.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.280306816101074\n",
      "mAP: 0.4247608780860901\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  8.46it/s, loss=40.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.391360827854704\n",
      "mAP: 0.5066418647766113\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.40it/s, loss=36.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.335917472839355\n",
      "mAP: 0.5494250655174255\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.42it/s, loss=37]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.39261777060373\n",
      "mAP: 0.49376457929611206\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=34.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.62103189740862\n",
      "mAP: 0.5031922459602356\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=32.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.23311519622803\n",
      "mAP: 0.5843014717102051\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=36.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.40741239275251\n",
      "mAP: 0.4294871985912323\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.48it/s, loss=34.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.30315889630999\n",
      "mAP: 0.43803125619888306\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.40it/s, loss=39.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.23646054949079\n",
      "mAP: 0.5927718877792358\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=31.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.14612007141113\n",
      "mAP: 0.44565075635910034\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  9.17it/s, loss=36.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.16287694658552\n",
      "mAP: 0.57020103931427\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.48it/s, loss=33.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.063074248177664\n",
      "mAP: 0.5071690082550049\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=36.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.07558604649135\n",
      "mAP: 0.45322081446647644\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=34.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.03742517743792\n",
      "mAP: 0.5115848183631897\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.54it/s, loss=46]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.87329987117222\n",
      "mAP: 0.5950696468353271\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=35.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.91912160600935\n",
      "mAP: 0.5873763561248779\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.43it/s, loss=45.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.86186300005232\n",
      "mAP: 0.48369359970092773\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=32]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.00687967027937\n",
      "mAP: 0.5798168778419495\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=35.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.93235111236572\n",
      "mAP: 0.4859074056148529\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  8.90it/s, loss=36.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.74133709498814\n",
      "mAP: 0.5983890891075134\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=41.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.82656955718994\n",
      "mAP: 0.5403066277503967\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=32.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.89184052603586\n",
      "mAP: 0.478191077709198\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=39.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.583437374659944\n",
      "mAP: 0.5612120628356934\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=46.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.455600193568635\n",
      "mAP: 0.4846818447113037\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=30.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.436160223824636\n",
      "mAP: 0.550643265247345\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.55it/s, loss=41.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.321020807538716\n",
      "mAP: 0.5387557148933411\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.42it/s, loss=37.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.47994899749756\n",
      "mAP: 0.5136318802833557\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.48it/s, loss=41.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.31685774666922\n",
      "mAP: 0.5350223183631897\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=39.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.34749344417027\n",
      "mAP: 0.4974035322666168\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.40it/s, loss=42.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.25040204184396\n",
      "mAP: 0.471844881772995\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=45.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.36309746333531\n",
      "mAP: 0.5542279481887817\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=41.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.2310425894601\n",
      "mAP: 0.5904659628868103\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=37.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.18779114314488\n",
      "mAP: 0.5859584212303162\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.42it/s, loss=47.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.13965320587158\n",
      "mAP: 0.5044952034950256\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=29.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.114608900887625\n",
      "mAP: 0.4983193874359131\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=38.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.99317060198103\n",
      "mAP: 0.5347381830215454\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=41.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.99298409053257\n",
      "mAP: 0.5044601559638977\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=55]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.903259822300505\n",
      "mAP: 0.5074084997177124\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=33.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.89807346888951\n",
      "mAP: 0.5550571084022522\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=33]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.97654179164341\n",
      "mAP: 0.5258854627609253\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.42it/s, loss=38.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.83904579707554\n",
      "mAP: 0.5278202295303345\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=36.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.88815416608538\n",
      "mAP: 0.5353260040283203\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=42.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.663921628679546\n",
      "mAP: 0.5191854238510132\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=38.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.63151809147426\n",
      "mAP: 0.5187008380889893\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.37it/s, loss=34.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.67621449061802\n",
      "mAP: 0.5164057016372681\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=35.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.573025703430176\n",
      "mAP: 0.5685111880302429\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=44.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.62068721226284\n",
      "mAP: 0.5235593914985657\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.40it/s, loss=36.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.62311363220215\n",
      "mAP: 0.5472506880760193\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.43it/s, loss=37.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.598521777561736\n",
      "mAP: 0.5544291138648987\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.40it/s, loss=36.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.46646513257708\n",
      "mAP: 0.543787956237793\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.40it/s, loss=32.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.37718268803188\n",
      "mAP: 0.5390440821647644\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=35.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.3934143611363\n",
      "mAP: 0.5391781330108643\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=39.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.275631359645296\n",
      "mAP: 0.539341926574707\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.33it/s, loss=35.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.263210024152485\n",
      "mAP: 0.5497182011604309\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.51it/s, loss=42.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.31690774645124\n",
      "mAP: 0.5407590270042419\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=34.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.2381649017334\n",
      "mAP: 0.5677105188369751\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=35.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.20728315625872\n",
      "mAP: 0.5463276505470276\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=42.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.26554911477225\n",
      "mAP: 0.5582868456840515\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.37it/s, loss=38.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.12296199798584\n",
      "mAP: 0.5601545572280884\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.51it/s, loss=28]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.16478518077305\n",
      "mAP: 0.5500228404998779\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.55it/s, loss=35.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.148619651794434\n",
      "mAP: 0.5423035621643066\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_fn(train_loader, model, optimizer, loss_fn)\n",
    "    pred_boxes, target_boxes, real_boxes = get_bboxes(\n",
    "        train_loader, model, threshold=0.1, distance_threshold=0.1\n",
    "    )\n",
    "    mAP = mean_average_precision(pred_boxes, real_boxes)\n",
    "    print(f\"mAP: {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13760, 1095)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_boxes), len(real_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.0,\n",
       " 0.531000018119812,\n",
       " 0.5211970210075378,\n",
       " 0.8059999942779541,\n",
       " 0.7431421279907227]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.0, 1.0, 0.531000018119812, 0.5211970210075378]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"fomo.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and make inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyissimoYOLO(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LinearActivation()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LinearActivation()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LinearActivation()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LinearActivation()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (fclayers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=3200, out_features=256, bias=True)\n",
       "    (2): LinearActivation()\n",
       "    (3): Linear(in_features=256, out_features=112, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpoint = torch.load(\"fomo.pth\")\n",
    "# Load the state dictionary from the .pth file\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.5861493349075317\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred_boxes, target_boxes, real_boxes = get_bboxes(\n",
    "        test_loader, model, threshold = 0.1, distance_threshold=0.1\n",
    "    )\n",
    "    mAP = mean_average_precision(pred_boxes, real_boxes)\n",
    "    print(f\"mAP: {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_centers(idx, pred_centers, target_centers):\n",
    "    values = test_dataset[idx]\n",
    "    image = values[0]\n",
    "    image = image.permute(1, 2, 0).to(\"cpu\")\n",
    "    \n",
    "    image = np.array(image)\n",
    "    height, width, _ = image.shape\n",
    "    p_centers = []\n",
    "    t_centers = []\n",
    "    for center in pred_centers:\n",
    "        if center[0] == idx:\n",
    "            p_centers.append(center[1:])\n",
    "    \n",
    "    for center in target_centers:\n",
    "        if center[0] == idx:\n",
    "            t_centers.append(center[1:])\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for center in p_centers:\n",
    "        rect = patches.Rectangle(\n",
    "            (center[2] * width , center[3] * height),\n",
    "            1,\n",
    "            1,\n",
    "            linewidth=5,\n",
    "            edgecolor=\"r\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Create a Rectangle patch\n",
    "    for boxes in t_centers:\n",
    "        class_label = int(boxes[0])\n",
    "        box = boxes[1:]\n",
    "        assert len(box) == 4, \"Got more values than in x, y, w, h, in a box!\"\n",
    "        upper_left_x = box[0] - box[2] / 2\n",
    "        upper_left_y = box[1] - box[3] / 2\n",
    "        rect = patches.Rectangle(\n",
    "            (upper_left_x * width, upper_left_y * height),\n",
    "            box[2] * width,\n",
    "            box[3] * height,\n",
    "            linewidth=1,\n",
    "            edgecolor=\"r\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add class label text\n",
    "        ax.text(upper_left_x * width, upper_left_y * height, str(class_label), color='r', fontsize=10, verticalalignment='bottom')\n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3293\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_centers(1, pred_boxes, real_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In red predicted, green true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.rand(1, 3, 256, 256).to(DEVICE)\n",
    "model.eval()\n",
    "output = model(sample)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the path to save the ONNX model\n",
    "onnx_model_path = \"fomo.onnx\"\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, sample, onnx_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYHELAYERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a subset of plain samples from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_list=[]\n",
    "test_label_list=[]\n",
    "for values in test_dataset:\n",
    "    image = values[0]\n",
    "    label = values[1]\n",
    "    test_img_list.append(image)\n",
    "    test_label_list.append(label)\n",
    "    if len(test_img_list)==1:\n",
    "        break\n",
    "\n",
    "test_img_array = np.array(test_img_list)\n",
    "test_label_array = np.array(test_label_list)\n",
    "# test_img_array = test_img_array[:11728]\n",
    "# test_label_array = test_label_array[:11728]\n",
    "# test_img_array = test_img_array.reshape(733,16,3,64,64)\n",
    "# test_label_array = test_label_array.reshape(733,16,7,7,30)\n",
    "print(test_img_array.shape)\n",
    "print(test_label_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize he scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhelayers\n",
    "import utilshe\n",
    "\n",
    "utilshe.verify_memory()\n",
    "\n",
    "print('Misc. initalizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pyhelayers.DefaultContext()\n",
    "print('HE context ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nnp = pyhelayers.NeuralNetPlain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "nnp.init_from_files(hyper_params, [\"fomo.onnx\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "he_run_req.set_he_context_options([pyhelayers.DefaultContext()])\n",
    "he_run_req.optimize_for_batch_size(1)\n",
    "\n",
    "profile = pyhelayers.HeModel.compile(nnp, he_run_req)\n",
    "batch_size = profile.get_optimal_batch_size()\n",
    "print('Profile ready. Batch size=',batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.get_he_config_requirement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pyhelayers.HeModel.create_context(profile)\n",
    "print('HE context initalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.get_scheme_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.get_default_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.get_library_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.has_secret_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.save_secret_key_to_file('secret_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = pyhelayers.NeuralNet(context)\n",
    "nn.encode_encrypt(nnp, profile)\n",
    "print('Encrypted network ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_samples, labels = utilshe.extract_batch(test_img_array, test_label_array, batch_size, 0)\n",
    "\n",
    "print('Batch of size',batch_size,'loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plain_samples.shape)\n",
    "print(plain_samples.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iop = nn.create_io_processor()\n",
    "samples = pyhelayers.EncryptedData(context)\n",
    "iop.encode_encrypt_inputs_for_predict(samples, [plain_samples])\n",
    "print('Test data encrypted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction on encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilshe.start_timer()\n",
    "\n",
    "predictions = pyhelayers.EncryptedData(context)\n",
    "nn.predict(predictions, samples)\n",
    "\n",
    "duration=utilshe.end_timer('predict')\n",
    "utilshe.report_duration('predict per sample',duration/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_predictions_aHE = iop.decrypt_decode_output(predictions)\n",
    "print(f\"plain prediction shape after HE: {plain_predictions_aHE.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(plain_predictions_aHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## In case I have test samples > batch size\n",
    "# plain_predictions_aHE = plain_predictions_aHE.reshape(,1470)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate prediction with HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_predictions_bHE=[]\n",
    "for sample in test_img_array:\n",
    "    tensor_sample = torch.tensor(sample).unsqueeze(0)\n",
    "    output = model(tensor_sample)\n",
    "    output = output.detach().numpy()\n",
    "    plain_predictions_bHE.append(output)\n",
    "plain_predictions_bHE = np.array(plain_predictions_bHE)\n",
    "plain_predictions_bHE = plain_predictions_bHE.reshape(1, 441)\n",
    "print(f\"plain prediction shape before HE: {plain_predictions_bHE.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the absolute differences between plain prediction before and after HE\n",
    "differences = np.abs(plain_predictions_bHE - plain_predictions_aHE)\n",
    "\n",
    "# Compute relevant statistics\n",
    "mean_difference = np.mean(differences)\n",
    "max_difference = np.max(differences)\n",
    "min_difference = np.min(differences)\n",
    "std_difference = np.std(differences)\n",
    "\n",
    "print(f\"Mean difference: {mean_difference}\")\n",
    "print(f\"Max difference: {max_difference}\")\n",
    "print(f\"Min difference: {min_difference}\")\n",
    "print(f\"Std difference: {std_difference}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert prediction in bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes_from_prediction(\n",
    "    predictions,\n",
    "    test_image_array,\n",
    "    iou_threshold,\n",
    "    threshold,\n",
    "):\n",
    "    all_pred_boxes = []\n",
    "\n",
    "    \n",
    "    train_idx = 0\n",
    "\n",
    "    bboxes = cellboxes_to_boxes(predictions)\n",
    "\n",
    "    for idx in range(len(test_image_array)):\n",
    "        image = test_image_array[idx]\n",
    "\n",
    "        nms_boxes = non_max_suppression(\n",
    "            bboxes[idx],\n",
    "            iou_threshold=iou_threshold,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "\n",
    "        # Activate only for test\n",
    "        if  idx == 0:\n",
    "            plot_image(image.permute(1,2,0).to(\"cpu\"), nms_boxes)\n",
    "\n",
    "        for nms_box in nms_boxes:\n",
    "            all_pred_boxes.append([train_idx] + nms_box)\n",
    "\n",
    "        \n",
    "\n",
    "        train_idx += 1\n",
    "\n",
    "    return all_pred_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_predaHE = torch.tensor(plain_predictions_aHE)\n",
    "tensor_predbHE = torch.tensor(plain_predictions_bHE)\n",
    "tensor_imgs = torch.tensor(test_img_array)\n",
    "\n",
    "print(\"Prediction before HE\")\n",
    "bboxes_aHE = get_bboxes_from_prediction(tensor_predbHE, tensor_imgs, iou_threshold=0.5, threshold=0.4)\n",
    "\n",
    "print(\"Prediction after HE\")\n",
    "bboxes_bHE = get_bboxes_from_prediction(tensor_predaHE, tensor_imgs, iou_threshold=0.5, threshold=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
