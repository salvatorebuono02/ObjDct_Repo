{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a tiny version of YOLO with DIOR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arch/ObjDct_Repo/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement YOLO architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearActivation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, t):\n",
    "        return torch.pow(t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyissimoYOLO(nn.Module):\n",
    "    def __init__(self, B=2, num_classes=1, S=4):\n",
    "        super(TinyissimoYOLO, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            LinearActivation(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            LinearActivation(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            LinearActivation(),\n",
    "            nn.AvgPool2d(kernel_size=2,stride = 2)\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            LinearActivation(),\n",
    "            nn.AvgPool2d(kernel_size=2,stride = 2)\n",
    "        )\n",
    "\n",
    "        self.fclayers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*5*5, 256),\n",
    "            LinearActivation(),\n",
    "            nn.Linear(256, S*S*(num_classes + 3 * B)),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        print(x.shape)\n",
    "        x = self.fclayers(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model = TinyissimoYOLO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyissimoYOLO                           [1, 112]                  --\n",
       "├─Sequential: 1-1                        [1, 16, 44, 44]           --\n",
       "│    └─Conv2d: 2-1                       [1, 16, 88, 88]           448\n",
       "│    └─LinearActivation: 2-2             [1, 16, 88, 88]           --\n",
       "│    └─AvgPool2d: 2-3                    [1, 16, 44, 44]           --\n",
       "├─Sequential: 1-2                        [1, 32, 22, 22]           --\n",
       "│    └─Conv2d: 2-4                       [1, 32, 44, 44]           4,640\n",
       "│    └─LinearActivation: 2-5             [1, 32, 44, 44]           --\n",
       "│    └─AvgPool2d: 2-6                    [1, 32, 22, 22]           --\n",
       "├─Sequential: 1-3                        [1, 64, 11, 11]           --\n",
       "│    └─Conv2d: 2-7                       [1, 64, 22, 22]           18,496\n",
       "│    └─LinearActivation: 2-8             [1, 64, 22, 22]           --\n",
       "│    └─AvgPool2d: 2-9                    [1, 64, 11, 11]           --\n",
       "├─Sequential: 1-4                        [1, 128, 5, 5]            --\n",
       "│    └─Conv2d: 2-10                      [1, 128, 11, 11]          73,856\n",
       "│    └─LinearActivation: 2-11            [1, 128, 11, 11]          --\n",
       "│    └─AvgPool2d: 2-12                   [1, 128, 5, 5]            --\n",
       "├─Sequential: 1-5                        [1, 112]                  --\n",
       "│    └─Flatten: 2-13                     [1, 3200]                 --\n",
       "│    └─Linear: 2-14                      [1, 256]                  819,456\n",
       "│    └─LinearActivation: 2-15            [1, 256]                  --\n",
       "│    └─Linear: 2-16                      [1, 112]                  28,784\n",
       "==========================================================================================\n",
       "Total params: 945,680\n",
       "Trainable params: 945,680\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 31.19\n",
       "==========================================================================================\n",
       "Input size (MB): 0.09\n",
       "Forward/backward pass size (MB): 1.86\n",
       "Params size (MB): 3.78\n",
       "Estimated Total Size (MB): 5.74\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(1, 3, 88, 88))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(center_preds, center_labels):\n",
    "    \"\"\"\n",
    "    Calculate euclidean distance\n",
    "    Parameters:\n",
    "        center_preds: predictions of centers (BATCH_SIZE, 2)\n",
    "        center_labels: target of centers of shape (BATCH_SIZE, 2)\n",
    "    Returns:\n",
    "        distance: euclidean distance for all examples\n",
    "    \"\"\"\n",
    "\n",
    "    x1 = center_preds[..., 0:1]\n",
    "    y1 = center_preds[..., 1:2]\n",
    "    x2 = center_labels[..., 0:1]\n",
    "    y2 = center_labels[..., 1:2]\n",
    "\n",
    "    distance = torch.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_center_inside_bbox(center, bbox):\n",
    "    \"\"\"\n",
    "    Check if a center (x, y) is inside a bounding box (x, y, w, h).\n",
    "    Parameters:\n",
    "        center (tuple): The (x, y) coordinates of the center.\n",
    "        bbox (tuple): The (x, y, w, h) coordinates of the bounding box.\n",
    "    Returns:\n",
    "        bool: True if the center is inside the bounding box, False otherwise.\n",
    "    \"\"\"\n",
    "    center_x, center_y = center\n",
    "    bbox_x, bbox_y, bbox_w, bbox_h = bbox\n",
    "\n",
    "    bbox_x_min = bbox_x - bbox_w / 2\n",
    "    bbox_x_max = bbox_x + bbox_w / 2\n",
    "    bbox_y_min = bbox_y - bbox_h / 2\n",
    "    bbox_y_max = bbox_y + bbox_h / 2\n",
    "\n",
    "    return bbox_x_min <= center_x <= bbox_x_max and bbox_y_min <= center_y <= bbox_y_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(\n",
    "    pred_boxes, true_boxes, num_classes=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates mean average precision \n",
    "    Parameters:\n",
    "        pred_boxes (list): list of lists containing all bboxes with each bbox\n",
    "        specified as [train_idx, class_prediction, prob_score, x_center, y_center]\n",
    "        true_boxes (list): Similar as pred_boxes except all the correct ones \n",
    "        specified as [train_idx, class_label, x, y, w, h]\n",
    "        num_classes (int): number of classes\n",
    "    Returns:\n",
    "        float: mAP value across all classes \n",
    "    \"\"\"\n",
    "    average_precisions = []\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        detections = []\n",
    "        ground_truths = []\n",
    "\n",
    "        for detection in pred_boxes:\n",
    "            if detection[1] == c:\n",
    "                detections.append(detection)\n",
    "\n",
    "        for true_box in true_boxes:\n",
    "            if true_box[1] == c:\n",
    "                ground_truths.append(true_box)\n",
    "\n",
    "        amount_bboxes = Counter([gt[0] for gt in ground_truths])\n",
    "\n",
    "        for key, val in amount_bboxes.items():\n",
    "            amount_bboxes[key] = torch.zeros(val)\n",
    "\n",
    "        detections.sort(key=lambda x: x[2], reverse=True)\n",
    "        TP = torch.zeros((len(detections)))\n",
    "        FP = torch.zeros((len(detections)))\n",
    "        total_true_bboxes = len(ground_truths)\n",
    "\n",
    "        if total_true_bboxes == 0:\n",
    "            continue\n",
    "\n",
    "        for detection_idx, detection in enumerate(detections):\n",
    "            ground_truth_img = [\n",
    "                bbox for bbox in ground_truths if bbox[0] == detection[0]\n",
    "            ]\n",
    "\n",
    "            best_match = False\n",
    "\n",
    "            for idx, gt in enumerate(ground_truth_img):\n",
    "                if is_center_inside_bbox(detection[3:5], gt[2:]):\n",
    "                    best_match = True\n",
    "                    best_gt_idx = idx\n",
    "                    break\n",
    "\n",
    "            if best_match:\n",
    "                if amount_bboxes[detection[0]][best_gt_idx] == 0:\n",
    "                    TP[detection_idx] = 1\n",
    "                    amount_bboxes[detection[0]][best_gt_idx] = 1\n",
    "                else:\n",
    "                    FP[detection_idx] = 1\n",
    "            else:\n",
    "                FP[detection_idx] = 1\n",
    "\n",
    "        TP_cumsum = torch.cumsum(TP, dim=0)\n",
    "        FP_cumsum = torch.cumsum(FP, dim=0)\n",
    "        recalls = TP_cumsum / (total_true_bboxes + epsilon)\n",
    "        precisions = torch.divide(TP_cumsum, (TP_cumsum + FP_cumsum + epsilon))\n",
    "        precisions = torch.cat((torch.tensor([1]), precisions))\n",
    "        recalls = torch.cat((torch.tensor([0]), recalls))\n",
    "        average_precisions.append(torch.trapz(precisions, recalls))\n",
    "\n",
    "    return sum(average_precisions) / len(average_precisions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Max Suppression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(centers, threshold, distance_threshold):\n",
    "\n",
    "    assert type(centers) == list\n",
    "    # centers = [center for center in centers if center[1]> threshold]\n",
    "    centers = sorted(centers, key=lambda x: x[1], reverse=True)\n",
    "    centers_after_nms = []\n",
    "\n",
    "    while centers:\n",
    "        current_center = centers.pop(0)\n",
    "        # centers = [\n",
    "        #     center\n",
    "        #     for center in centers\n",
    "        #     if center[0] != current_center[0]\n",
    "        #     or euclidean_distance(\n",
    "        #         torch.tensor(current_center[3:5]).unsqueeze(0),\n",
    "        #         torch.tensor(center[3:5]).unsqueeze(0),\n",
    "        #     )\n",
    "        #     > distance_threshold\n",
    "        # ]\n",
    "\n",
    "        centers_after_nms.append(current_center)\n",
    "        break\n",
    "        \n",
    "    return centers_after_nms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and convert centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(\n",
    "    loader,\n",
    "    model,\n",
    "    threshold,\n",
    "    distance_threshold,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    all_pred_centers = []\n",
    "    all_true_centers = []\n",
    "    all_true_boxes = []\n",
    "\n",
    "    # make sure model is in eval before get bboxes\n",
    "    model.eval()\n",
    "    train_idx = 0\n",
    "\n",
    "    for batch_idx, (x, labels, boxes_list) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(x)\n",
    "\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        true_centers = cellcenters_to_centers(labels) # type: ignore\n",
    "        pred_centers = cellcenters_to_centers(predictions) # type: ignore\n",
    "        \n",
    "        \n",
    "\n",
    "        for idx in range(batch_size):\n",
    "\n",
    "            boxes = boxes_list[idx].to(device)\n",
    "\n",
    "            nms_centers= non_max_suppression(\n",
    "                pred_centers[idx],\n",
    "                threshold=threshold,\n",
    "                distance_threshold=distance_threshold,\n",
    "            )\n",
    "\n",
    "            for center in nms_centers:\n",
    "                all_pred_centers.append([train_idx] + center)\n",
    "\n",
    "            # for center in pred_centers[idx]:\n",
    "            #     if center[1] > 0:\n",
    "            #         all_pred_centers.append([train_idx] + center)\n",
    "\n",
    "            for center in true_centers[idx]:\n",
    "                if center[1] > 0:\n",
    "                    all_true_centers.append([train_idx] + center)\n",
    "\n",
    "            for box in boxes:\n",
    "                all_true_boxes.append([train_idx] + box.tolist())\n",
    "\n",
    "            train_idx += 1\n",
    "\n",
    "    model.train()\n",
    "    return all_pred_centers, all_true_centers, all_true_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cellcenters(predictions, S=4, C=1):\n",
    "    \"\"\"\n",
    "    Converts predictions from the model to centers\n",
    "    \"\"\"\n",
    "    predictions = predictions.to(\"cpu\")\n",
    "    batch_size = predictions.shape[0]\n",
    "    predictions = predictions.reshape(batch_size, S, S, C + 6)\n",
    "\n",
    "    centers1 = predictions[..., C + 1:C + 3]\n",
    "    centers2 = predictions[..., C + 4:C + 6]\n",
    "    \n",
    "    scores = torch.cat(\n",
    "        (predictions[..., C].unsqueeze(0), predictions[..., C + 3].unsqueeze(0)), dim=0\n",
    "    )\n",
    "    best_center = scores.argmax(0).unsqueeze(-1)\n",
    "\n",
    "    best_centers = centers1 * (1 - best_center) + best_center * centers2\n",
    "\n",
    "    # This results in a tensor with shape (batch_size, 7, 7, 1) where each element represents the index of a grid cell.\n",
    "    cell_indices = torch.arange(S).repeat(batch_size, S, 1).unsqueeze(-1)\n",
    "    x = 1 / S * (best_centers[..., :1] + cell_indices)\n",
    "    # Permute because is used here to swap these indices to match the (x, y) convention used in the best_boxes tensor.\n",
    "    # [0,1,2]->[0,0,0]\n",
    "    # [0,1,2]->[1,1,1]\n",
    "    # [0,1,2]->[2,2,2]\n",
    "    y = 1 / S * (best_centers[..., 1:2] + cell_indices.permute(0, 2, 1, 3))\n",
    "    converted_centers = torch.cat((x, y), dim=-1)\n",
    "    predicted_class = predictions[..., :C].argmax(-1).unsqueeze(-1)\n",
    "    best_confidence = torch.max(predictions[..., C], predictions[..., C + 3]).unsqueeze(\n",
    "        -1\n",
    "    )\n",
    "    \n",
    "    converted_preds = torch.cat(\n",
    "        (predicted_class, best_confidence, converted_centers), dim=-1\n",
    "    )\n",
    "\n",
    "    return converted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cellcenters_to_centers(out, S=4):\n",
    "    converted_pred = convert_cellcenters(out).reshape(out.shape[0], S * S, -1)\n",
    "    converted_pred[..., 0] = converted_pred[..., 0].long()\n",
    "    all_centers = []\n",
    "\n",
    "    for ex_idx in range(out.shape[0]):\n",
    "        centers = []\n",
    "        for center_idx in range(S * S):\n",
    "            centers.append([x.item() for x in converted_pred[ex_idx, center_idx, :]])\n",
    "        all_centers.append(centers)\n",
    "        \n",
    "    return all_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Loader of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, centers):\n",
    "        for t in self.transforms:\n",
    "            img, centers = t(img), centers\n",
    "\n",
    "        return img, centers\n",
    "\n",
    "\n",
    "transform = Compose([transforms.Resize((88, 88)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, S=4, B=2, C=1, transform=None, train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.train = train\n",
    "\n",
    "        # Determine the directory of the images and labels\n",
    "        self.img_dir = os.path.join(self.root_dir, 'images')\n",
    "        self.label_dir = os.path.join(self.root_dir, 'label')\n",
    "\n",
    "        self.img_ids = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.img_ids[index].split('.')[0]\n",
    "        centers = []\n",
    "        boxes = []\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, img_id + '.jpg')\n",
    "        image = Image.open(img_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        # Load labels\n",
    "        label_path = os.path.join(self.label_dir, img_id + '.txt')\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                class_label, x, y, width, height = map(float, line.strip().split())\n",
    "                centers.append([class_label, x, y])\n",
    "                boxes.append([class_label, x, y, width, height])\n",
    "        \n",
    "        if len(boxes) > 3:\n",
    "            boxes = boxes[:3]\n",
    "            centers = centers[:3]\n",
    "\n",
    "        boxes = torch.tensor(boxes)\n",
    "        centers = torch.tensor(centers)        \n",
    "        if self.transform:\n",
    "            image, centers = self.transform(image, centers)\n",
    "        # Convert To Cells\n",
    "        label_matrix = torch.zeros((self.S, self.S, self.C + 3 * self.B))\n",
    "        for center in centers:\n",
    "            class_label, x, y = center\n",
    "            class_label = int(class_label)\n",
    "            i, j = int(self.S * y), int(self.S * x)\n",
    "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
    "\n",
    "            if label_matrix[i, j, self.C] == 0:\n",
    "                label_matrix[i, j, self.C] = 1\n",
    "\n",
    "                center_coordinates = torch.tensor(\n",
    "                    [x_cell, y_cell]\n",
    "                )\n",
    "\n",
    "                label_matrix[i, j, self.C + 1:self.C + 3] = center_coordinates\n",
    "                label_matrix[i, j, class_label] = 1\n",
    "    \n",
    "        #print(f\"label_matrix shape: {label_matrix.shape}\")\n",
    "\n",
    "        return image, label_matrix , boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From original paper: \n",
    ">   YOLO predicts multiple bounding boxes per grid cell. At training time we only want one bounding box predictor to be responsible for each object. We assign one predictor to be “responsible” for predicting an object based on which prediction has the highest current IOU with the ground truth. This leads to specialization between the bounding box predictors.\n",
    "Each predictor gets better at predicting certain sizes, aspect ratios, or classes of object, improving overall recall. \n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\lambda_{\\text {coord }} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(x_i-\\hat{x}_i\\right)^2+\\left(y_i-\\hat{y}_i\\right)^2\\right] \\\\\n",
    "+\\lambda_{\\text {coord }} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {obj }}\\left[\\left(\\sqrt{w_i}-\\sqrt{\\hat{w}_i}\\right)^2+\\left(\\sqrt{h_i}-\\sqrt{\\hat{h}_i}\\right)^2\\right] \\\\\n",
    "+\\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {obj }}\\left(C_i-\\hat{C}_i\\right)^2 \\\\\n",
    "+\\lambda_{\\text {noobj }} \\sum_{i=0}^{S^2} \\sum_{j=0}^B \\mathbb{1}_{i j}^{\\text {noobj }}\\left(C_i-\\hat{C}_i\\right)^2 \\\\\n",
    "+\\sum_{i=0}^{S^2} \\mathbb{1}_i^{\\text {obj }} \\sum_{c \\in \\text { classes }}\\left(p_i(c)-\\hat{p}_i(c)\\right)^2\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "During training we optimize the following, multi-part where $ 1_{obj}^i $ denotes if object appears in cell **i** and $1_{obj}^{ij}$ denotes that the **j**  bounding box predictor in cell i is “responsible” for that prediction.\n",
    "\n",
    "In every image many grid cells do not contain any object. This pushes the “confidence” scores of those cells towards zero, often overpowering the gradient from cells that do contain objects. This can lead to model instability, as the model may prioritize learning to predict empty cells rather than focusing on correctly detecting objects in cells containing them, causing training to diverge early on. To remedy this, we increase the loss from bounding box coordinate predictions and decrease the loss from confidence predictions for boxes that don’t contain objects. We use two parameters, $\\lambda_{coord}$ and $\\lambda_{noobj}$  to accomplish this.\n",
    "\n",
    "Note that the loss function only penalizes classification error if an object is present in that grid cell (hence the conditional class probability discussed earlier). It also only penalizes bounding box coordinate error if that predictor is “responsible” for the ground truth box (i.e. has the highest\n",
    "IOU of any predictor in that grid cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculate the loss for yolo (v1) model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, S=4, B=2, C=1):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "        \"\"\"\n",
    "        S is split size of image (in paper 7),\n",
    "        B is number of boxes (in paper 2),\n",
    "        C is number of classes (in paper 20, in dataset 3),\n",
    "        \"\"\"\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        # These are from Yolo paper, signifying how much we should\n",
    "        # pay loss for no object (noobj) and the box coordinates (coord)\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        # predictions are shaped (BATCH_SIZE, S*S(C+B*3) when inputted\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 3)\n",
    "        # Calculate IoU for the two predicted bounding boxes with target bbox\n",
    "        iou_c1 = euclidean_distance(predictions[..., self.C + 1:self.C + 3], target[..., self.C + 1:self.C + 3])\n",
    "        iou_c2 = euclidean_distance(predictions[..., self.C + 4:self.C + 6], target[..., self.C + 1:self.C + 3])\n",
    "        ious = torch.cat([iou_c1.unsqueeze(0), iou_c2.unsqueeze(0)], dim=0)\n",
    "        # Take the box with highest IoU out of the two prediction\n",
    "        # Note that bestbox will be indices of 0, 1 for which bbox was best\n",
    "        iou_maxes, bestcenter = torch.max(ious, dim=0)\n",
    "        exists_center = target[..., self.C].unsqueeze(3)  # in paper this is Iobj_i\n",
    "        \n",
    "        # ======================== #\n",
    "        #   FOR CENTER COORDINATES #\n",
    "        # ======================== #\n",
    "\n",
    "        # Set boxes with no object in them to 0. We only take out one of the two \n",
    "        # predictions, which is the one with highest Iou calculated previously.\n",
    "\n",
    "        center_predictions = exists_center * (\n",
    "            (\n",
    "                bestcenter * predictions[..., self.C + 4:self.C + 6]\n",
    "                + (1 - bestcenter) * predictions[..., self.C + 1:self.C + 3]\n",
    "            )\n",
    "        )\n",
    "        center_targets = exists_center * target[..., self.C + 1:self.C + 3]\n",
    "\n",
    "        center_loss = self.mse(\n",
    "            torch.flatten(center_predictions, end_dim=-2),\n",
    "            torch.flatten(center_targets, end_dim=-2),\n",
    "        )\n",
    "\n",
    "        # ==================== #\n",
    "        #   FOR OBJECT LOSS    #\n",
    "        # ==================== #\n",
    "\n",
    "        # pred_box is the confidence score for the bbox with highest IoU\n",
    "        pred_center = (\n",
    "            bestcenter * predictions[..., self.C + 3:self.C + 4] + (1 - bestcenter) * predictions[..., self.C:self.C + 1]\n",
    "        )\n",
    "\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_center * pred_center),\n",
    "            torch.flatten(exists_center * target[..., self.C:self.C + 1]),\n",
    "        )\n",
    "\n",
    "        # ======================= #\n",
    "        #   FOR NO OBJECT LOSS    #\n",
    "        # ======================= #\n",
    "\n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1 - exists_center) * predictions[..., self.C:self.C + 1], start_dim=1),\n",
    "            torch.flatten((1 - exists_center) * target[..., self.C:self.C + 1], start_dim=1),\n",
    "        )\n",
    "\n",
    "        no_object_loss += self.mse(\n",
    "            torch.flatten((1 - exists_center) * predictions[..., self.C + 3:self.C + 4], start_dim=1),\n",
    "            torch.flatten((1 - exists_center) * target[..., self.C:self.C + 1], start_dim=1)\n",
    "        )\n",
    "\n",
    "        # ================== #\n",
    "        #   FOR CLASS LOSS   #\n",
    "        # ================== #\n",
    "\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_center * predictions[..., :self.C], end_dim=-2,),\n",
    "            torch.flatten(exists_center * target[..., :self.C], end_dim=-2,),\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            self.lambda_coord * center_loss  # first two rows in paper\n",
    "            + object_loss  # third row in paper\n",
    "            + self.lambda_noobj * no_object_loss  # forth row\n",
    "            + class_loss  # fifth row\n",
    "        )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 32 # 64 in original paper but resource exhausted error otherwise.\n",
    "WEIGHT_DECAY = 0\n",
    "EPOCHS = 100\n",
    "LOAD_MODEL = False\n",
    "LOAD_MODEL_FILE = \"fomo.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, optimizer, loss_fn):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    mean_loss = []\n",
    "    \n",
    "    for batch_idx, (x, y,boxes) in enumerate(loop):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        mean_loss.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss = loss.item())\n",
    "        \n",
    "    print(f\"Mean loss was {sum(mean_loss) / len(mean_loss)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    label_matrices = []\n",
    "    boxes_list = []\n",
    "    for item in batch:\n",
    "        images.append(item[0])\n",
    "        label_matrices.append(item[1])\n",
    "        boxes_list.append(item[2])\n",
    "    images = torch.stack(images)\n",
    "    label_matrices = torch.stack(label_matrices)\n",
    "    return images, label_matrices, boxes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arch/ObjDct_Repo/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "files_dir = 'one_class_data'\n",
    "model = TinyissimoYOLO().to(DEVICE)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience=3, mode='max', verbose=True)\n",
    "loss_fn = YoloLoss()\n",
    "\n",
    "\n",
    "train_dataset = DiorDataset(\n",
    "    root_dir=files_dir,\n",
    "    transform=transform,\n",
    "    train=True\n",
    ")\n",
    "\n",
    "\n",
    "# Define the length of the training set\n",
    "train_len = int(0.8 * len(train_dataset))\n",
    "\n",
    "# Define the length of the test set\n",
    "test_len = len(train_dataset) - train_len\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(train_dataset, [train_len, test_len])\n",
    "\n",
    "# Now you can create your DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:03<00:00,  8.58it/s, loss=101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 174.22255870274134\n",
      "mAP: 0.09050809592008591\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=59.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 104.30295780726841\n",
      "mAP: 0.504238486289978\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=40.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 72.09068502698626\n",
      "mAP: 0.520530641078949\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.61it/s, loss=44]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 63.390579632350374\n",
      "mAP: 0.5111578702926636\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.62it/s, loss=48.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 58.91898659297398\n",
      "mAP: 0.5166173577308655\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.57it/s, loss=43]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 56.42841270991734\n",
      "mAP: 0.5126722455024719\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.59it/s, loss=39.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 54.761153084891184\n",
      "mAP: 0.5141769647598267\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.56it/s, loss=46.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 53.46169063023159\n",
      "mAP: 0.5127039551734924\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=35]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 52.668761934552876\n",
      "mAP: 0.5240744352340698\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.57it/s, loss=40.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 52.20018359592983\n",
      "mAP: 0.5201159119606018\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.42it/s, loss=32.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 51.49714265550886\n",
      "mAP: 0.5200673937797546\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.48it/s, loss=41.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 51.21327917916434\n",
      "mAP: 0.519405722618103\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=50.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 51.003764969961985\n",
      "mAP: 0.5225948691368103\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.37it/s, loss=39]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.547630310058594\n",
      "mAP: 0.5235791206359863\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=45]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.25765677860805\n",
      "mAP: 0.5292503237724304\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=51.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 50.123277936662944\n",
      "mAP: 0.5330635905265808\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.42it/s, loss=48]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.904118401663645\n",
      "mAP: 0.536175012588501\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=30.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.778352056230815\n",
      "mAP: 0.5442169308662415\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=34]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.66613238198416\n",
      "mAP: 0.5412673950195312\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.43it/s, loss=33.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.598189217703684\n",
      "mAP: 0.5507544875144958\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.48it/s, loss=45.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.634721347263884\n",
      "mAP: 0.5411509871482849\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=36.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.57550062452044\n",
      "mAP: 0.5464120507240295\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=41.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.419501304626465\n",
      "mAP: 0.5570517778396606\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=37.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.30964796883719\n",
      "mAP: 0.5428768396377563\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=35]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.4200645174299\n",
      "mAP: 0.5500411987304688\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=31]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.323496614183696\n",
      "mAP: 0.5519428849220276\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=43.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.27685410635812\n",
      "mAP: 0.5519179701805115\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.39it/s, loss=40.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.20636054447719\n",
      "mAP: 0.5478022694587708\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.42it/s, loss=26.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.10495185852051\n",
      "mAP: 0.5453470349311829\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=32.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.12581198556082\n",
      "mAP: 0.5530819892883301\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=37.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.096884318760466\n",
      "mAP: 0.5495049357414246\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=35.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.267354420253206\n",
      "mAP: 0.5565057992935181\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.55it/s, loss=34.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.09332806723459\n",
      "mAP: 0.5510268211364746\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.57it/s, loss=41.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.96155275617327\n",
      "mAP: 0.5528923273086548\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.56it/s, loss=34.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.03038311004639\n",
      "mAP: 0.5523631572723389\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.61it/s, loss=40.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.76801463535854\n",
      "mAP: 0.5575427412986755\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.59it/s, loss=44.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.02766881670271\n",
      "mAP: 0.5576030015945435\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=39.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.177855355399\n",
      "mAP: 0.5576362013816833\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.59it/s, loss=38.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.027865409851074\n",
      "mAP: 0.5558281540870667\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.57it/s, loss=32]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.000126702444895\n",
      "mAP: 0.5619609355926514\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=43.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 49.133118629455566\n",
      "mAP: 0.5520700812339783\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=38.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.706336293901714\n",
      "mAP: 0.5553754568099976\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.57it/s, loss=32.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.79246439252581\n",
      "mAP: 0.5645220875740051\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=42.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.61051164354597\n",
      "mAP: 0.5597938895225525\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.51it/s, loss=41]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.5207576751709\n",
      "mAP: 0.5585213899612427\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.51it/s, loss=49.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.53167833600725\n",
      "mAP: 0.5597553253173828\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.58it/s, loss=35]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.641881125313894\n",
      "mAP: 0.5514532327651978\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.55it/s, loss=33]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.639584405081614\n",
      "mAP: 0.5550190806388855\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=43.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.57708631243025\n",
      "mAP: 0.5555254220962524\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.41it/s, loss=36.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.482461384364534\n",
      "mAP: 0.5466006994247437\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.43it/s, loss=33.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.25813743046352\n",
      "mAP: 0.5692135691642761\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=32.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.2328006199428\n",
      "mAP: 0.557380735874176\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.36it/s, loss=34.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.34309468950544\n",
      "mAP: 0.5582126975059509\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.43it/s, loss=29]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.44871759414673\n",
      "mAP: 0.5522138476371765\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=36.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.21078600202288\n",
      "mAP: 0.5534117221832275\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.54it/s, loss=37.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.219746589660645\n",
      "mAP: 0.5481794476509094\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=46.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.185307775224956\n",
      "mAP: 0.5462011694908142\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=42.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.27018765040806\n",
      "mAP: 0.5530688166618347\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=42]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.993404797145296\n",
      "mAP: 0.562818706035614\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.40it/s, loss=40]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 48.04655006953648\n",
      "mAP: 0.5582764744758606\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=36.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.80715669904436\n",
      "mAP: 0.5460052490234375\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.35it/s, loss=39.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.91867882864816\n",
      "mAP: 0.5449930429458618\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=39.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.976985931396484\n",
      "mAP: 0.5593197345733643\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=43.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.84378269740513\n",
      "mAP: 0.543369710445404\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=29.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.70293058667864\n",
      "mAP: 0.5584465265274048\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=40.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.800165448869976\n",
      "mAP: 0.5539671182632446\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.37it/s, loss=39.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.64272553580148\n",
      "mAP: 0.5571547746658325\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.51it/s, loss=33.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.67733751024519\n",
      "mAP: 0.5525665879249573\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=32.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.70797484261649\n",
      "mAP: 0.559015154838562\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=41.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.53396538325718\n",
      "mAP: 0.5525856614112854\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=40.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.48660959516253\n",
      "mAP: 0.5595557689666748\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=43.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.586608614240376\n",
      "mAP: 0.5498638153076172\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=30.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.733871596200125\n",
      "mAP: 0.5595291256904602\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=32.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.791520254952566\n",
      "mAP: 0.5497651696205139\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.48it/s, loss=31.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.8394513130188\n",
      "mAP: 0.546882152557373\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=37.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.319455691746306\n",
      "mAP: 0.5600360631942749\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=38.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.333993911743164\n",
      "mAP: 0.5584977865219116\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.53it/s, loss=33.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.201391083853586\n",
      "mAP: 0.5607253313064575\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=39.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.22560841696603\n",
      "mAP: 0.5581804513931274\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=38]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.3958922794887\n",
      "mAP: 0.5496358275413513\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.48it/s, loss=38.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.49620723724365\n",
      "mAP: 0.5558828115463257\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.48it/s, loss=35.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.238137926374165\n",
      "mAP: 0.5567349195480347\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=29.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.32838944026402\n",
      "mAP: 0.559733510017395\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=41.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 47.32177816118513\n",
      "mAP: 0.5590006709098816\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.51it/s, loss=39]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.99934836796352\n",
      "mAP: 0.5473154187202454\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.39it/s, loss=31.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.98408957890102\n",
      "mAP: 0.5508463382720947\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.52it/s, loss=27.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.969397272382466\n",
      "mAP: 0.5597578287124634\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=37.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.9910113470895\n",
      "mAP: 0.5440802574157715\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.45it/s, loss=37.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.9229929787772\n",
      "mAP: 0.5611598491668701\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.39it/s, loss=31.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.80109773363386\n",
      "mAP: 0.5486170053482056\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=33.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.814676829746794\n",
      "mAP: 0.5461055636405945\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.43it/s, loss=46.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.67426054818289\n",
      "mAP: 0.5607511401176453\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.47it/s, loss=42.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.72469793047224\n",
      "mAP: 0.554796040058136\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.42it/s, loss=43.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.65267549242292\n",
      "mAP: 0.5560261011123657\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.44it/s, loss=34.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.70555441720145\n",
      "mAP: 0.5561373829841614\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.49it/s, loss=33.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.609759194510325\n",
      "mAP: 0.5496708750724792\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.50it/s, loss=40.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.56198024749756\n",
      "mAP: 0.5554682016372681\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.46it/s, loss=38.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.52369253976004\n",
      "mAP: 0.5589553117752075\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.48it/s, loss=33]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.39498424530029\n",
      "mAP: 0.5624595284461975\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:02<00:00,  9.54it/s, loss=39.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss was 46.379413332257954\n",
      "mAP: 0.5607389807701111\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_fn(train_loader, model, optimizer, loss_fn)\n",
    "    pred_boxes, target_boxes, real_boxes = get_bboxes(\n",
    "        train_loader, model, threshold=0.4, distance_threshold=0.1\n",
    "    )\n",
    "    mAP = mean_average_precision(pred_boxes, real_boxes)\n",
    "    print(f\"mAP: {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 1090)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_boxes), len(real_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.0,\n",
       " 0.37599998712539673,\n",
       " 0.38288289308547974,\n",
       " 0.7480000257492065,\n",
       " 0.6576576828956604]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.0, 1.0, 0.37599998712539673, 0.38288289308547974]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_boxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"fomo.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and make inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyissimoYOLO(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LinearActivation()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LinearActivation()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LinearActivation()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LinearActivation()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (fclayers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=3200, out_features=256, bias=True)\n",
       "    (2): LinearActivation()\n",
       "    (3): Linear(in_features=256, out_features=112, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpoint = torch.load(\"fomo.pth\")\n",
    "# Load the state dictionary from the .pth file\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.5647098422050476\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred_boxes, target_boxes, real_boxes = get_bboxes(\n",
    "        test_loader, model, threshold = 0.4, distance_threshold=0.1\n",
    "    )\n",
    "    mAP = mean_average_precision(pred_boxes, real_boxes)\n",
    "    print(f\"mAP: {mAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_centers(idx, pred_centers, target_centers):\n",
    "    values = test_dataset[idx]\n",
    "    image = values[0]\n",
    "    image = image.permute(1, 2, 0).to(\"cpu\")\n",
    "    \n",
    "    image = np.array(image)\n",
    "    height, width, _ = image.shape\n",
    "    p_centers = []\n",
    "    t_centers = []\n",
    "    for center in pred_centers:\n",
    "        if center[0] == idx:\n",
    "            p_centers.append(center[1:])\n",
    "    \n",
    "    for center in target_centers:\n",
    "        if center[0] == idx:\n",
    "            t_centers.append(center[1:])\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for center in p_centers:\n",
    "        rect = patches.Rectangle(\n",
    "            (center[2] * width , center[3] * height),\n",
    "            1,\n",
    "            1,\n",
    "            linewidth=5,\n",
    "            edgecolor=\"r\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Create a Rectangle patch\n",
    "    for boxes in t_centers:\n",
    "        class_label = int(boxes[0])\n",
    "        box = boxes[1:]\n",
    "        assert len(box) == 4, \"Got more values than in x, y, w, h, in a box!\"\n",
    "        upper_left_x = box[0] - box[2] / 2\n",
    "        upper_left_y = box[1] - box[3] / 2\n",
    "        rect = patches.Rectangle(\n",
    "            (upper_left_x * width, upper_left_y * height),\n",
    "            box[2] * width,\n",
    "            box[3] * height,\n",
    "            linewidth=1,\n",
    "            edgecolor=\"r\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add class label text\n",
    "        ax.text(upper_left_x * width, upper_left_y * height, str(class_label), color='r', fontsize=10, verticalalignment='bottom')\n",
    "\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_centers(1, pred_boxes, real_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In red predicted, green true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.rand(1, 3, 256, 256).to(DEVICE)\n",
    "model.eval()\n",
    "output = model(sample)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the path to save the ONNX model\n",
    "onnx_model_path = \"fomo.onnx\"\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, sample, onnx_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYHELAYERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a subset of plain samples from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_list=[]\n",
    "test_label_list=[]\n",
    "for values in test_dataset:\n",
    "    image = values[0]\n",
    "    label = values[1]\n",
    "    test_img_list.append(image)\n",
    "    test_label_list.append(label)\n",
    "    if len(test_img_list)==1:\n",
    "        break\n",
    "\n",
    "test_img_array = np.array(test_img_list)\n",
    "test_label_array = np.array(test_label_list)\n",
    "# test_img_array = test_img_array[:11728]\n",
    "# test_label_array = test_label_array[:11728]\n",
    "# test_img_array = test_img_array.reshape(733,16,3,64,64)\n",
    "# test_label_array = test_label_array.reshape(733,16,7,7,30)\n",
    "print(test_img_array.shape)\n",
    "print(test_label_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize he scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhelayers\n",
    "import utilshe\n",
    "\n",
    "utilshe.verify_memory()\n",
    "\n",
    "print('Misc. initalizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pyhelayers.DefaultContext()\n",
    "print('HE context ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nnp = pyhelayers.NeuralNetPlain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "nnp.init_from_files(hyper_params, [\"fomo.onnx\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "he_run_req.set_he_context_options([pyhelayers.DefaultContext()])\n",
    "he_run_req.optimize_for_batch_size(1)\n",
    "\n",
    "profile = pyhelayers.HeModel.compile(nnp, he_run_req)\n",
    "batch_size = profile.get_optimal_batch_size()\n",
    "print('Profile ready. Batch size=',batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.get_he_config_requirement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = pyhelayers.HeModel.create_context(profile)\n",
    "print('HE context initalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.get_scheme_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.get_default_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.get_library_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.has_secret_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.save_secret_key_to_file('secret_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = pyhelayers.NeuralNet(context)\n",
    "nn.encode_encrypt(nnp, profile)\n",
    "print('Encrypted network ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_samples, labels = utilshe.extract_batch(test_img_array, test_label_array, batch_size, 0)\n",
    "\n",
    "print('Batch of size',batch_size,'loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plain_samples.shape)\n",
    "print(plain_samples.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iop = nn.create_io_processor()\n",
    "samples = pyhelayers.EncryptedData(context)\n",
    "iop.encode_encrypt_inputs_for_predict(samples, [plain_samples])\n",
    "print('Test data encrypted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction on encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilshe.start_timer()\n",
    "\n",
    "predictions = pyhelayers.EncryptedData(context)\n",
    "nn.predict(predictions, samples)\n",
    "\n",
    "duration=utilshe.end_timer('predict')\n",
    "utilshe.report_duration('predict per sample',duration/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_predictions_aHE = iop.decrypt_decode_output(predictions)\n",
    "print(f\"plain prediction shape after HE: {plain_predictions_aHE.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(plain_predictions_aHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## In case I have test samples > batch size\n",
    "# plain_predictions_aHE = plain_predictions_aHE.reshape(,1470)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate prediction with HE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_predictions_bHE=[]\n",
    "for sample in test_img_array:\n",
    "    tensor_sample = torch.tensor(sample).unsqueeze(0)\n",
    "    output = model(tensor_sample)\n",
    "    output = output.detach().numpy()\n",
    "    plain_predictions_bHE.append(output)\n",
    "plain_predictions_bHE = np.array(plain_predictions_bHE)\n",
    "plain_predictions_bHE = plain_predictions_bHE.reshape(1, 441)\n",
    "print(f\"plain prediction shape before HE: {plain_predictions_bHE.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the absolute differences between plain prediction before and after HE\n",
    "differences = np.abs(plain_predictions_bHE - plain_predictions_aHE)\n",
    "\n",
    "# Compute relevant statistics\n",
    "mean_difference = np.mean(differences)\n",
    "max_difference = np.max(differences)\n",
    "min_difference = np.min(differences)\n",
    "std_difference = np.std(differences)\n",
    "\n",
    "print(f\"Mean difference: {mean_difference}\")\n",
    "print(f\"Max difference: {max_difference}\")\n",
    "print(f\"Min difference: {min_difference}\")\n",
    "print(f\"Std difference: {std_difference}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert prediction in bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes_from_prediction(\n",
    "    predictions,\n",
    "    test_image_array,\n",
    "    iou_threshold,\n",
    "    threshold,\n",
    "):\n",
    "    all_pred_boxes = []\n",
    "\n",
    "    \n",
    "    train_idx = 0\n",
    "\n",
    "    bboxes = cellboxes_to_boxes(predictions)\n",
    "\n",
    "    for idx in range(len(test_image_array)):\n",
    "        image = test_image_array[idx]\n",
    "\n",
    "        nms_boxes = non_max_suppression(\n",
    "            bboxes[idx],\n",
    "            iou_threshold=iou_threshold,\n",
    "            threshold=threshold,\n",
    "        )\n",
    "\n",
    "        # Activate only for test\n",
    "        if  idx == 0:\n",
    "            plot_image(image.permute(1,2,0).to(\"cpu\"), nms_boxes)\n",
    "\n",
    "        for nms_box in nms_boxes:\n",
    "            all_pred_boxes.append([train_idx] + nms_box)\n",
    "\n",
    "        \n",
    "\n",
    "        train_idx += 1\n",
    "\n",
    "    return all_pred_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_predaHE = torch.tensor(plain_predictions_aHE)\n",
    "tensor_predbHE = torch.tensor(plain_predictions_bHE)\n",
    "tensor_imgs = torch.tensor(test_img_array)\n",
    "\n",
    "print(\"Prediction before HE\")\n",
    "bboxes_aHE = get_bboxes_from_prediction(tensor_predbHE, tensor_imgs, iou_threshold=0.5, threshold=0.4)\n",
    "\n",
    "print(\"Prediction after HE\")\n",
    "bboxes_bHE = get_bboxes_from_prediction(tensor_predaHE, tensor_imgs, iou_threshold=0.5, threshold=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
